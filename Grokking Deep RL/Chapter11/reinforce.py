# -*- coding: utf-8 -*-
"""REINFORCE

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pMXq_i7v9_OrVdqCuWfsPgOqG9bJRFC0
"""

#Google colab file 
#Created by ashutoshtiwari13
import warnings
warnings.filterwarnings('ignore')

import torch 
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.multiprocessing as mp
import threading 

import numpy as np 
from collections import namedtuple, deque
import matplotlib.pyplot as plt
import matplotlib.pylab as pylab
from itertools import cycle, count

# Commented out IPython magic to ensure Python compatibility.
import matplotlib
import gym
import os
import io
import sys
import time 

# %matplotlib inline

class CartPoleEnvV1(gym.Wrapper):
  def __init__(self,env):
    gym.Wrapper.__init__(self,env)
  def reset(self, **kwargs):
    return self.env.reset(**kwargs)
  def step(self, action):
    next_state, reward,done, info = self.env.step(action)
    (x, x_dot, theta, theta_dot) = next_state
    pole_fall = x < -self.env.unwrapped.x_threshold or x > self.env.unwrapped.x_threshold or theta < -self.env.unwrapped.theta_threshold_radians or theta >  self.env.unwrapped.theta_threshold_radians
    reward = -1 if pole_fell else 0
    return next_state, reward, done, info

class CartPoleEnvV2(gym.Wrapper):
  def __init__(self,env):
    gym.Wrapper.__init__(self,env)
  def reset(self, **kwargs):
    return self.env.reset(**kwargs)
  def step(self, action):
    next_state, reward,done, info = self.env.step(action)
    (x, x_dot, theta, theta_dot) = next_state
    pole_fall = x < -self.env.unwrapped.x_threshold or x > self.env.unwrapped.x_threshold or theta < -self.env.unwrapped.theta_threshold_radians or theta >  self.env.unwrapped.theta_threshold_radians
    
    if done:
      if pole_fell:
        reward=0
      else:
        reward = self.env._max_episode_steps
    return next_state, reward, done, info

class NN_arch(nn.Module):
  def __init__(Self, input_dim, output_dim, hidden_dim=(32,32),activation = F.relu):
    super(NN_arch, self).__init__()
    self.activation = activation
    self.input = nn.Linear(input_dim , hidden_dims[0])
    self.hidden_layers = nn.ModuleList()
    for i in range(len(hidden_dims)-1):
      hidden = nn.Linear(hidden_dims[i],hidden_dims[i+1])
      self.hidden.append(hidden)
    self.output = nn.Linear(hidden_dims[-1],output_dim)

  def stateChange(self, state):
    """
    Making sure the state is the type of variable and shape before passing to the NN_arch
    """
    x = state
    if not isinstance(x, torch.Tensor):
      x = torch.tensor(x, dtype= torch.float32)
      x = x.unsqueeze(0)

    x = self.activation(self.input(x))
    for h in hidden:
      x = self.activation(hidden)
    return self.output(x)
  
  def fowardProp(self, state):
    logits = self.stateChange(state)
    dist = torch.distributions.Categorical(logits=logits)
    action = dist.sample()
    logpa = dist.log_prob(action).unsqueeze(-1)
    entropy = dist.entropy().unsqueeze(-1)
    is_exploratory = action != np.argmax(logits.detach().numpy())
    return action.item(), is_exploratory.item(),logpa,entropy